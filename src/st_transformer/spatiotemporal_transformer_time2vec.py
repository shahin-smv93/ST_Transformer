# -*- coding: utf-8 -*-
"""Spatiotemporal_Transformer_Time2Vec.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1moSR-chDVHYZnwOkLTCxZ_4uH9uucDjk
"""

import torch
from torch import nn

class Time2Vec(nn.Module):
  def __init__(self, input_dim=None, embed_dim=None, act_function=torch.sin):
    assert embed_dim % input_dim == 0
    super(Time2Vec, self).__init__()
    self.enabled = embed_dim > 0
    if self.enabled:
      self.embed_dim = embed_dim // input_dim
      self.input_dim = input_dim
      self.embed_weight = nn.parameter.Parameter(
          torch.randn(self.input_dim, self.embed_dim))
      self.embed_bias = nn.parameter.Parameter(
          torch.randn(self.input_dim, self.embed_dim))
      self.act_function = act_function

  def forward(self, x):
    if self.enabled:
      x = torch.diag_embed(x)
      x_affine = torch.matmul(x, self.embed_weight) + self.embed_bias
      x_affine_0, x_affine_1 = torch.split(x_affine, [1, self.embed_dim - 1], dim=-1)
      x_affine_1 = self.act_function(x_affine_1)
      x_output = torch.cat([x_affine_0, x_affine_1], dim=-1)
      x_output = x_output.view(x_output.shape[0], x_output.shape[1], -1)
    else:
      x_output = x
    return x_output